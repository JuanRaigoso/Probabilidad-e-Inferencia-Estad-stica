---
title: "Unidad N°2 - Métodos y simulación estadística"
subtitle: "Ejercicio N° 2"
author: "Juan David Raigoso Espinosa"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: lume
    toc: yes
    toc_float:
      collapsed: true
---

::: text-justify
# PROBLEMA 2.

## Propiedades de los estimadores.

La simulación ayuda a entender y validad las propiedades de los estimadores estadísticos como son: insesgadez, eficiencia y la consistencia principalmente. El siguiente problema permite evidenciar las principales características de un grupo de estimadores propuestos para la estimación de un parámetro asociado a un modelo de probabilidad. 
Sean $X_1, X_2, X_3$ y $X_4$, una muestra aleatoria de tamaño n=4 cuya población la conforma una distribución exponencial con parámetro θ desconocido. Determine las características de cada uno de los siguientes estimadores propuestos:

```{r}
library(ggplot2)
# semilla
set.seed(123)

# Definimos las muestra - cantidad de simulaciones
n_muestras <- c(20, 50, 100, 1000)

# valor del parámetro θ
theta <- 5

# Almacenamos los resultados
resultados <- list()

# Se realizan las  simulaciones
for (n in n_muestras) {
  num_simulaciones <- n  # Ajustamos el número de simulaciones a n
  
  # Creamos los estimadores
  estimadores <- list(
    Estimador_1 = function(x) (x[1] + x[2])/6 + (x[3] + x[4])/3,
    Estimador_2 = function(x) (x[1] + 2*x[2] + 3*x[3] + 4*x[4])/5,
    Estimador_3 = function(x) sum(x)/4,
    Estimador_4 = function(x) (min(x) + max(x))/2
  )
  simulaciones <- matrix(rexp(4 * num_simulaciones, rate = 1/theta), nrow = num_simulaciones)
  
  estimaciones <- matrix(apply(simulaciones, 1, function(x) sapply(estimadores, function(est) est(x))), nrow = num_simulaciones)
  
  sesgos <- colMeans(estimaciones) - theta
  eficiencias <- 1 / colMeans((estimaciones - theta)^2)
  consistencias <- colMeans((estimaciones - theta)^2)
  
  medias <- colMeans(estimaciones)
  varianzas <- apply(estimaciones, 2, var)
  
  resultados[[as.character(n)]] <- data.frame(Estimador = names(estimadores), N = n, Sesgo = sesgos, Eficiencia = eficiencias,
                                              Consistencia = consistencias, Media = medias,
                                              Varianza = varianzas)
}
```


$$  a) \hat{\theta}_1=\frac{(X_1+X_2)}6 + \frac{(X_3+X_4)}3$$



$$  b) \hat{\theta}_2=\frac{(X_1+2X_2+3X_3+4X_4)}5$$


$$  c) \hat{\theta}_3= \frac{X_1+X_2+X_3+X_4}4 $$

$$  d) \hat{\theta}_4=\frac{min(X_1+X_2+X_3+X_4)+max({X_1+X_2+X_3+X_4})}2$$
```{r}
# Unimos los resultados en un DataFrame
resultados_df <- do.call(rbind, resultados)
rownames(resultados_df) <- NULL

# Resultados por cada parametro y propiedad
print(resultados_df)

# tema para las gráficas
theme_set(theme_minimal())

#  Propiedad Sesgo -Gráfica
sesgo_plot <- ggplot(resultados_df, aes(x = Estimador, y = Sesgo)) +
  geom_boxplot() +
  labs(title = "Sesgo", y = "Valor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Propiedad Eficiencia - Gráfica
eficiencia_plot <- ggplot(resultados_df, aes(x = Estimador, y = Eficiencia)) +
  geom_boxplot() +
  labs(title = "Eficiencia", y = "Valor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Propiedad Consistencia - Gráfica 
consistencia_plot <- ggplot(resultados_df, aes(x = Estimador, y = Consistencia)) +
  geom_boxplot() +
  labs(title = "Consistencia", y = "Valor") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Mostrar las gráficas
print(sesgo_plot)
print(eficiencia_plot)
print(consistencia_plot)

```

Nota: Genere unas muestras de n=20, 50, 100 y 1000 para cada uno de los estimadores planteados.
En cada caso evalué las propiedades de insesgadez, eficiencia y consistencia
Suponga un valor para el parámetro θ


## Análisis de resultados.

Teniendo en cuenta los resultados de las propiedades de sesgo, eficiencia y consistencia, podemos decir que, a nivel de **sesgo** el cual se refiere a cuán cerca está el estimador del valor verdadero del parámetro. Para este caso todos los valores de los parámetros son positivos, lo que indica que tienden a sobrestimar el parámetro θ. Entre los cuatro estimadores, el ***estimador 2*** tiende a tener el menor sesgo para todos los tamaños de muestra, ya que este en varios casos tiene el sesgo más bajo.
Con relación a propiedad de **eficiencia** la cual se relaciona con la precisión del estimador. El ***Estimador 2*** muestra una eficiencia relativamente alta en algunos casos, especialmente con un tamaño de muestra de 100. Es decir, un estimador eficiente tiene una varianza baja, por lo cual dicho estimador proporciona estimaciones más precisas en términos de varianza.
Por último, la propiedad de la **consistencia** nos dice si el estimador tiende a converger al valor verdadero del parámetro a medida que aumenta el tamaño de la muestra. Observando los valores de consistencia, el  ***Estimador 3*** parecen mostrar una mejor consistencia en varios casos, especialmente en muestras grandes.
En relación a la **Media** y **Varianza**: Si consideramos la media y la varianza de las estimaciones, puedes observar que "Estimador_2" tiende a tener la media más baja y la varianza más baja en varios casos. Esto indica que es consistente en términos de sesgo y eficiencia.

## Conclusión.
En conclusión, definir cuál es el mejor estimador según los datos arrojados, es muy complejo. Pues se tendría que dar un valor especial o mayor a alguna propiedad de los estimadores, es decir, si valoramos la insesgadez, el estimador 2 es la mejor alternativa. Si priorizamos la propiedad de eficacia, el estimador 2 es más preferible. Si buscamos un estimador consistente el ***estimador 3*** es la mejor elección.


:::
